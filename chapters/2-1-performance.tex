
\section{Performance}

In computing performance can be defined by two factors,
computational requirements or resources.
Computational requirements can be thought of "what needs to be done?", or efficacy,
and computational resources can be thought in terms of "how much will it cost?", or efficiency.

\begin{equation}
    \mathnormal{Performace} \sim \frac{1}{\mathnormal{Resources~for~solution}}
\end{equation}

\subsection{Expectations}

In a scenario where we have $p$ processors and each processor is rated at $f$ MFLOP, should we see $f \times p$ MFLOPS performance?

The answer is not as simple as "yes".
Several causes may affect performance, while causes may interact with each other,
they need to be understood separately.

\subsection{Embarrassingly Parallel Computations}

Or for short EPCs, are computations that can be trivially divided into several independent parts able to be executed simultaneously.
For \textit{truly} EPCs there should be no interaction between processes, while in \textit{nearly} EPCs the input and output is required to be distributed and combined in some way.

EPCs have potential to achieve maximal speedups in parallel platforms.


\subsection{Scalability}
As previously discussed the performance of a parallel solution is subjected to several factors, namely scalability.
Scalability is the ability of a parallel algorithm of achieving performance gains proportional to the number of processors and the size of the problem.

\paragraph{Evaluation}

To evaluate scalability we can start from the following metrics.

\begin{itemize}
    \item Sequential Runtime ($T_{seq}$) which is a function of problem size and architecture.
    \item Parallel Runtime ($T_{par}$) which is a function of problem size and parallel architecture, that is the number of processors used in execution.
\end{itemize}

With that in mind we can define the speedup $S_p$ as \autoref{eq:speedup},
efficiency $E_p$ as \autoref{eq:efficiency}
and finally the cost $C_p$ as \autoref{eq:cost},
where $p$ is the number of available processors and $T_p$ is the execution time on a $p$ processor system\sidenote{A parallel algorithm is cost-optimal if $C_p = T_1$ or equivalently $E_p = 1$}.

\begin{equation}\label{eq:speedup}
    S_p = \frac{T_1}{T_p}
\end{equation}

\begin{equation}\label{eq:efficiency}
    E_p = \frac{S_p}{p}
\end{equation}

\begin{equation}\label{eq:cost}
    C_p = p \times T_p
\end{equation}